{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:36:19.218685Z",
     "iopub.status.busy": "2022-05-22T16:36:19.218415Z",
     "iopub.status.idle": "2022-05-22T16:36:26.869440Z",
     "shell.execute_reply": "2022-05-22T16:36:26.868515Z",
     "shell.execute_reply.started": "2022-05-22T16:36:19.218659Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import unicodedata\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import STOPWORDS, WordCloud\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Embedding, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:36:37.019179Z",
     "iopub.status.busy": "2022-05-22T16:36:37.018877Z",
     "iopub.status.idle": "2022-05-22T16:36:44.633467Z",
     "shell.execute_reply": "2022-05-22T16:36:44.632430Z",
     "shell.execute_reply.started": "2022-05-22T16:36:37.019144Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q contractions==0.0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:37:01.642257Z",
     "iopub.status.busy": "2022-05-22T16:37:01.641908Z",
     "iopub.status.idle": "2022-05-22T16:37:02.923292Z",
     "shell.execute_reply": "2022-05-22T16:37:02.922369Z",
     "shell.execute_reply.started": "2022-05-22T16:37:01.642223Z"
    }
   },
   "outputs": [],
   "source": [
    "filename1 = '../input/news-summary/news_summary.csv'\n",
    "filename2 = '../input/news-summary/news_summary_more.csv'\n",
    "\n",
    "df1 = pd.read_csv(filename1, encoding='iso-8859-1').reset_index(drop=True)\n",
    "df2 = pd.read_csv(filename2, encoding='iso-8859-1').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:37:04.924808Z",
     "iopub.status.busy": "2022-05-22T16:37:04.924522Z",
     "iopub.status.idle": "2022-05-22T16:37:04.977728Z",
     "shell.execute_reply": "2022-05-22T16:37:04.977001Z",
     "shell.execute_reply.started": "2022-05-22T16:37:04.924782Z"
    }
   },
   "outputs": [],
   "source": [
    "df1_columns = df1.columns.tolist()\n",
    "df1_columns.remove('headlines') #The headlines column will be treated as summary for the text\n",
    "df1_columns.remove('text')\n",
    "df1.drop(df1_columns, axis='columns', inplace=True)\n",
    "\n",
    "df = pd.concat([df1, df2], axis='rows')\n",
    "del df1, df2\n",
    "\n",
    "# Shuffling the df\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformer Model Implementation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:37:25.139949Z",
     "iopub.status.busy": "2022-05-22T16:37:25.139438Z",
     "iopub.status.idle": "2022-05-22T16:37:25.212720Z",
     "shell.execute_reply": "2022-05-22T16:37:25.211999Z",
     "shell.execute_reply.started": "2022-05-22T16:37:25.139913Z"
    }
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "#df.head(5)\n",
    "document = df['text']\n",
    "summary = df['headlines']\n",
    "#summary=headlines; document=text\n",
    "summary = summary.apply(lambda x: '<go> ' + x + ' <stop>')\n",
    "#summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:37:36.826950Z",
     "iopub.status.busy": "2022-05-22T16:37:36.826210Z",
     "iopub.status.idle": "2022-05-22T16:37:52.932569Z",
     "shell.execute_reply": "2022-05-22T16:37:52.931484Z",
     "shell.execute_reply.started": "2022-05-22T16:37:36.826910Z"
    }
   },
   "outputs": [],
   "source": [
    "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
    "oov_token = '<unk>'\n",
    "document_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
    "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
    "document_tokenizer.fit_on_texts(document)\n",
    "summary_tokenizer.fit_on_texts(summary)\n",
    "inputs = document_tokenizer.texts_to_sequences(document)\n",
    "targets = summary_tokenizer.texts_to_sequences(summary)\n",
    "encoder_vocab_size = len(document_tokenizer.word_index) + 1\n",
    "decoder_vocab_size = len(summary_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:37:55.951828Z",
     "iopub.status.busy": "2022-05-22T16:37:55.951537Z",
     "iopub.status.idle": "2022-05-22T16:37:56.125014Z",
     "shell.execute_reply": "2022-05-22T16:37:56.124058Z",
     "shell.execute_reply.started": "2022-05-22T16:37:55.951795Z"
    }
   },
   "outputs": [],
   "source": [
    "document_lengths = pd.Series([len(x) for x in document])\n",
    "summary_lengths = pd.Series([len(x) for x in summary])\n",
    "document_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:37:59.135035Z",
     "iopub.status.busy": "2022-05-22T16:37:59.134709Z",
     "iopub.status.idle": "2022-05-22T16:37:59.146767Z",
     "shell.execute_reply": "2022-05-22T16:37:59.145948Z",
     "shell.execute_reply.started": "2022-05-22T16:37:59.135001Z"
    }
   },
   "outputs": [],
   "source": [
    "summary_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:01.791315Z",
     "iopub.status.busy": "2022-05-22T16:38:01.790851Z",
     "iopub.status.idle": "2022-05-22T16:38:01.795480Z",
     "shell.execute_reply": "2022-05-22T16:38:01.794869Z",
     "shell.execute_reply.started": "2022-05-22T16:38:01.791286Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_maxlen = 375 #Taking it 75th percentile \n",
    "decoder_maxlen = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:05.830448Z",
     "iopub.status.busy": "2022-05-22T16:38:05.830014Z",
     "iopub.status.idle": "2022-05-22T16:38:09.033645Z",
     "shell.execute_reply": "2022-05-22T16:38:09.032550Z",
     "shell.execute_reply.started": "2022-05-22T16:38:05.830419Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')\n",
    "\n",
    "inputs = tf.cast(inputs, dtype=tf.int32)\n",
    "targets = tf.cast(targets, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:09.328050Z",
     "iopub.status.busy": "2022-05-22T16:38:09.327719Z",
     "iopub.status.idle": "2022-05-22T16:38:09.331819Z",
     "shell.execute_reply": "2022-05-22T16:38:09.331219Z",
     "shell.execute_reply.started": "2022-05-22T16:38:09.328018Z"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:12.356583Z",
     "iopub.status.busy": "2022-05-22T16:38:12.355938Z",
     "iopub.status.idle": "2022-05-22T16:38:12.363403Z",
     "shell.execute_reply": "2022-05-22T16:38:12.362533Z",
     "shell.execute_reply.started": "2022-05-22T16:38:12.356538Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:14.586195Z",
     "iopub.status.busy": "2022-05-22T16:38:14.585870Z",
     "iopub.status.idle": "2022-05-22T16:38:14.594087Z",
     "shell.execute_reply": "2022-05-22T16:38:14.593283Z",
     "shell.execute_reply.started": "2022-05-22T16:38:14.586163Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_angles(position, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return position * angle_rates\n",
    "  \n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:17.435150Z",
     "iopub.status.busy": "2022-05-22T16:38:17.434385Z",
     "iopub.status.idle": "2022-05-22T16:38:17.441171Z",
     "shell.execute_reply": "2022-05-22T16:38:17.440393Z",
     "shell.execute_reply.started": "2022-05-22T16:38:17.435114Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "  \n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Building Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:20.657727Z",
     "iopub.status.busy": "2022-05-22T16:38:20.656944Z",
     "iopub.status.idle": "2022-05-22T16:38:20.664286Z",
     "shell.execute_reply": "2022-05-22T16:38:20.663203Z",
     "shell.execute_reply.started": "2022-05-22T16:38:20.657694Z"
    }
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:23.674133Z",
     "iopub.status.busy": "2022-05-22T16:38:23.673843Z",
     "iopub.status.idle": "2022-05-22T16:38:23.678554Z",
     "shell.execute_reply": "2022-05-22T16:38:23.677881Z",
     "shell.execute_reply.started": "2022-05-22T16:38:23.674106Z"
    }
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:26.127626Z",
     "iopub.status.busy": "2022-05-22T16:38:26.126782Z",
     "iopub.status.idle": "2022-05-22T16:38:26.143802Z",
     "shell.execute_reply": "2022-05-22T16:38:26.142466Z",
     "shell.execute_reply.started": "2022-05-22T16:38:26.127566Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "            \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:31.357586Z",
     "iopub.status.busy": "2022-05-22T16:38:31.357257Z",
     "iopub.status.idle": "2022-05-22T16:38:31.363045Z",
     "shell.execute_reply": "2022-05-22T16:38:31.362132Z",
     "shell.execute_reply.started": "2022-05-22T16:38:31.357557Z"
    }
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:33.924830Z",
     "iopub.status.busy": "2022-05-22T16:38:33.924182Z",
     "iopub.status.idle": "2022-05-22T16:38:33.934067Z",
     "shell.execute_reply": "2022-05-22T16:38:33.933212Z",
     "shell.execute_reply.started": "2022-05-22T16:38:33.924785Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:36.874744Z",
     "iopub.status.busy": "2022-05-22T16:38:36.874064Z",
     "iopub.status.idle": "2022-05-22T16:38:36.886006Z",
     "shell.execute_reply": "2022-05-22T16:38:36.885191Z",
     "shell.execute_reply.started": "2022-05-22T16:38:36.874703Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:42.475502Z",
     "iopub.status.busy": "2022-05-22T16:38:42.474897Z",
     "iopub.status.idle": "2022-05-22T16:38:42.485329Z",
     "shell.execute_reply": "2022-05-22T16:38:42.484392Z",
     "shell.execute_reply.started": "2022-05-22T16:38:42.475465Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:46.213767Z",
     "iopub.status.busy": "2022-05-22T16:38:46.213470Z",
     "iopub.status.idle": "2022-05-22T16:38:46.225194Z",
     "shell.execute_reply": "2022-05-22T16:38:46.224371Z",
     "shell.execute_reply.started": "2022-05-22T16:38:46.213736Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        return x, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:38:59.181425Z",
     "iopub.status.busy": "2022-05-22T16:38:59.180858Z",
     "iopub.status.idle": "2022-05-22T16:38:59.189626Z",
     "shell.execute_reply": "2022-05-22T16:38:59.188654Z",
     "shell.execute_reply.started": "2022-05-22T16:38:59.181391Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:39:07.760143Z",
     "iopub.status.busy": "2022-05-22T16:39:07.759404Z",
     "iopub.status.idle": "2022-05-22T16:39:07.764649Z",
     "shell.execute_reply": "2022-05-22T16:39:07.763759Z",
     "shell.execute_reply.started": "2022-05-22T16:39:07.760107Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyper-params\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:39:10.296617Z",
     "iopub.status.busy": "2022-05-22T16:39:10.296321Z",
     "iopub.status.idle": "2022-05-22T16:39:10.303729Z",
     "shell.execute_reply": "2022-05-22T16:39:10.302882Z",
     "shell.execute_reply.started": "2022-05-22T16:39:10.296587Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:39:12.591860Z",
     "iopub.status.busy": "2022-05-22T16:39:12.591032Z",
     "iopub.status.idle": "2022-05-22T16:39:12.598226Z",
     "shell.execute_reply": "2022-05-22T16:39:12.597412Z",
     "shell.execute_reply.started": "2022-05-22T16:39:12.591807Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:39:14.467364Z",
     "iopub.status.busy": "2022-05-22T16:39:14.466816Z",
     "iopub.status.idle": "2022-05-22T16:39:14.471866Z",
     "shell.execute_reply": "2022-05-22T16:39:14.471045Z",
     "shell.execute_reply.started": "2022-05-22T16:39:14.467323Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:39:17.200253Z",
     "iopub.status.busy": "2022-05-22T16:39:17.199558Z",
     "iopub.status.idle": "2022-05-22T16:39:17.222633Z",
     "shell.execute_reply": "2022-05-22T16:39:17.222003Z",
     "shell.execute_reply.started": "2022-05-22T16:39:17.200220Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:39:19.750465Z",
     "iopub.status.busy": "2022-05-22T16:39:19.749795Z",
     "iopub.status.idle": "2022-05-22T16:39:20.788790Z",
     "shell.execute_reply": "2022-05-22T16:39:20.787881Z",
     "shell.execute_reply.started": "2022-05-22T16:39:19.750427Z"
    }
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers, \n",
    "    d_model, \n",
    "    num_heads, \n",
    "    dff,\n",
    "    encoder_vocab_size, \n",
    "    decoder_vocab_size, \n",
    "    pe_input=encoder_vocab_size, \n",
    "    pe_target=decoder_vocab_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:39:23.834245Z",
     "iopub.status.busy": "2022-05-22T16:39:23.833907Z",
     "iopub.status.idle": "2022-05-22T16:39:23.840045Z",
     "shell.execute_reply": "2022-05-22T16:39:23.839145Z",
     "shell.execute_reply.started": "2022-05-22T16:39:23.834212Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:39:28.925410Z",
     "iopub.status.busy": "2022-05-22T16:39:28.924933Z",
     "iopub.status.idle": "2022-05-22T16:39:28.931493Z",
     "shell.execute_reply": "2022-05-22T16:39:28.930792Z",
     "shell.execute_reply.started": "2022-05-22T16:39:28.925375Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:39:32.116951Z",
     "iopub.status.busy": "2022-05-22T16:39:32.116301Z",
     "iopub.status.idle": "2022-05-22T16:39:32.124494Z",
     "shell.execute_reply": "2022-05-22T16:39:32.123692Z",
     "shell.execute_reply.started": "2022-05-22T16:39:32.116904Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, tar_inp, \n",
    "            True, \n",
    "            enc_padding_mask, \n",
    "            combined_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:39:37.343375Z",
     "iopub.status.busy": "2022-05-22T16:39:37.342474Z",
     "iopub.status.idle": "2022-05-22T19:29:38.387264Z",
     "shell.execute_reply": "2022-05-22T19:29:38.384771Z",
     "shell.execute_reply.started": "2022-05-22T16:39:37.343312Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "\n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        # 55k samples\n",
    "        # we display 3 batch results -- 0th, middle and last one (approx)\n",
    "        # 55k / 64 ~ 858; 858 / 2 = 429\n",
    "        if batch % 429 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T19:36:39.716812Z",
     "iopub.status.busy": "2022-05-22T19:36:39.716369Z",
     "iopub.status.idle": "2022-05-22T19:36:39.735384Z",
     "shell.execute_reply": "2022-05-22T19:36:39.734512Z",
     "shell.execute_reply.started": "2022-05-22T19:36:39.716763Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(input_document):\n",
    "    input_document = document_tokenizer.texts_to_sequences([input_document])\n",
    "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "\n",
    "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
    "\n",
    "    decoder_input = [summary_tokenizer.word_index[\"<go>\"]]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(decoder_maxlen):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "\n",
    "        predictions, attention_weights = transformer(\n",
    "            encoder_input, \n",
    "            output,\n",
    "            False,\n",
    "            enc_padding_mask,\n",
    "            combined_mask,\n",
    "            dec_padding_mask\n",
    "        )\n",
    "\n",
    "        predictions = predictions[: ,-1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        if predicted_id == summary_tokenizer.word_index[\"<stop>\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T19:36:42.959915Z",
     "iopub.status.busy": "2022-05-22T19:36:42.959454Z",
     "iopub.status.idle": "2022-05-22T19:36:42.965603Z",
     "shell.execute_reply": "2022-05-22T19:36:42.964694Z",
     "shell.execute_reply.started": "2022-05-22T19:36:42.959869Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize(input_document):\n",
    "    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n",
    "    summarized = evaluate(input_document=input_document)[0].numpy()\n",
    "    summarized = np.expand_dims(summarized[1:], 0)  # not printing <go> token\n",
    "    return summary_tokenizer.sequences_to_texts(summarized)[0]  # since there is just one translated document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T19:36:46.277246Z",
     "iopub.status.busy": "2022-05-22T19:36:46.276692Z",
     "iopub.status.idle": "2022-05-22T19:36:50.651972Z",
     "shell.execute_reply": "2022-05-22T19:36:50.651242Z",
     "shell.execute_reply.started": "2022-05-22T19:36:46.277205Z"
    }
   },
   "outputs": [],
   "source": [
    "full_text=\"US-based private equity firm General Atlantic is in talks to invest about \\\n",
    "    $850 million to $950 million in Reliance Industries' digital unit Jio \\\n",
    "    Platforms, the Bloomberg reported. Saudi Arabia's $320 billion sovereign \\\n",
    "    wealth fund is reportedly also exploring a potential investment in the \\\n",
    "    Mukesh Ambani-led company. The 'Public Investment Fund' is looking to \\\n",
    "    acquire a minority stake in Jio Platforms.\"\n",
    "\n",
    "abstract_text= summarize(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T19:37:20.594230Z",
     "iopub.status.busy": "2022-05-22T19:37:20.593922Z",
     "iopub.status.idle": "2022-05-22T19:37:20.603205Z",
     "shell.execute_reply": "2022-05-22T19:37:20.602309Z",
     "shell.execute_reply.started": "2022-05-22T19:37:20.594199Z"
    }
   },
   "outputs": [],
   "source": [
    "abstract_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ROUGE Score***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T19:37:04.049726Z",
     "iopub.status.busy": "2022-05-22T19:37:04.048698Z",
     "iopub.status.idle": "2022-05-22T19:37:12.482480Z",
     "shell.execute_reply": "2022-05-22T19:37:12.481636Z",
     "shell.execute_reply.started": "2022-05-22T19:37:04.049690Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T19:37:52.796518Z",
     "iopub.status.busy": "2022-05-22T19:37:52.796199Z",
     "iopub.status.idle": "2022-05-22T19:37:52.815317Z",
     "shell.execute_reply": "2022-05-22T19:37:52.814094Z",
     "shell.execute_reply.started": "2022-05-22T19:37:52.796488Z"
    }
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "ROUGE = Rouge()\n",
    "ROUGE.get_scores(full_text, abstract_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
